{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import io\n",
    "\n",
    "import csv \n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import glob \n",
    "\n",
    "import random \n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename \"holder\" folder \n",
    "zip_files = os.listdir('WedgeZips/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of headers\n",
    "headers = [\"datetime\",\"register_no\",\"emp_no\",\"trans_no\",\"upc\",\"description\",\"trans_type\",\n",
    "           \"trans_subtype\",\"trans_status\",\"department\",\"quantity\",\"Scale\",\"cost\",\"unitPrice\",\"total\",\n",
    "           \"regPrice\",\"altPrice\",\"tax\",\"taxexempt\",\"foodstamp\",\"wicable\",\"discount\",\"memDiscount\",\"discountable\",\n",
    "           \"discounttype\",\"voided\",\"percentDiscount\",\"ItemQtty\",\"volDiscType\",\"volume\",\"VolSpecial\",\"mixMatch\",\n",
    "           \"matched\",\"memType\",\"staff\",\"numflag\",\"itemstatus\",\"tenderstatus\",\"charflag\",\"varflag\",\"batchHeaderID\",\n",
    "           \"local\",\"organic\",\"display\",\"receipt\",\"card_no\",\"store\",\"branch\",\"match_id\",\"trans_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new directory \n",
    "temp_folder_name = \"wedge_clean/\"\n",
    "\n",
    "if not os.path.isdir(temp_folder_name) :\n",
    "    os.mkdir(temp_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transArchive_201410_201412.zip\n",
      "transArchive_201301_201303_inactive.zip\n",
      "transArchive_201210_201212.zip\n",
      "transArchive_201609.zip\n",
      "transArchive_201608.zip\n",
      "transArchive_201201_201203.zip\n",
      "transArchive_201204_201206.zip\n",
      "transArchive_201407_201409.zip\n",
      "transArchive_201207_201209.zip\n",
      "transArchive_201404_201406.zip\n",
      "transArchive_201401_201403.zip\n",
      "transArchive_201404_201406_inactive.zip\n",
      "transArchive_201210_201212_inactive.zip\n",
      "transArchive_201307_201309_inactive.zip\n",
      "transArchive_201501_201503.zip\n",
      "transArchive_201307_201309.zip\n",
      "transArchive_201504_201506.zip\n",
      "transArchive_201304_201306.zip\n",
      "transArchive_201507_201509.zip\n",
      "transArchive_201301_201303.zip\n",
      "transArchive_201204_201206_inactive.zip\n",
      "transArchive_201410_201412_inactive.zip\n",
      "transArchive_201310_201312.zip\n",
      "transArchive_201106.zip\n",
      "transArchive_201110_201112.zip\n",
      "transArchive_201701.zip\n",
      "transArchive_201310_201312_inactive.zip\n",
      "transArchive_201105.zip\n",
      "transArchive_201104.zip\n",
      "transArchive_201510.zip\n",
      "transArchive_201201_201203_inactive.zip\n",
      "transArchive_201101_201103.zip\n",
      "transArchive_201107_201109.zip\n",
      "transArchive_201511.zip\n",
      "transArchive_201407_201409_inactive.zip\n",
      "transArchive_201512.zip\n",
      "transArchive_201603.zip\n",
      "transArchive_201304_201306_inactive.zip\n",
      "transArchive_201602.zip\n",
      "transArchive_201007_201009.zip\n",
      "transArchive_201001_201003.zip\n",
      "transArchive_201601.zip\n",
      "transArchive_201004_201006.zip\n",
      "transArchive_201207_201209_inactive.zip\n",
      "transArchive_201605.zip\n",
      "transArchive_201611.zip\n",
      "transArchive_201610.zip\n",
      "transArchive_201604.zip\n",
      "transArchive_201612.zip\n",
      "transArchive_201606.zip\n",
      "transArchive_201010_201012.zip\n",
      "transArchive_201401_201403_inactive.zip\n",
      "transArchive_201607.zip\n",
      "Zip-A-Dee-Doo-Da\n"
     ]
    }
   ],
   "source": [
    "# Unzipping files, clean the files, add them to zip_clean folder \n",
    "\n",
    "# For zip file in zipfiles, read the file in the directory and assign a new name for the files inside\n",
    "for zip_file in zip_files : \n",
    "    print(zip_file)\n",
    "    \n",
    "    with ZipFile(\"WedgeZips/\" + zip_file, 'r') as my_zip_file :\n",
    "        files_inside = my_zip_file.namelist()\n",
    "        \n",
    "        for zipped_file in files_inside :\n",
    "            sniffer = csv.Sniffer()\n",
    "            \n",
    "            # Open and read input files then rename new files\n",
    "            with my_zip_file.open(zipped_file,'r') as input_file :\n",
    "                clean_file_name = input_file.name.replace('.csv','_clean.csv') \n",
    "                \n",
    "                # Open new output file names in new folder, write files and join headers to new outfile\n",
    "                with open(\"wedge_clean/\" + clean_file_name,'w') as outfile :\n",
    "                    outfile.write(\",\".join(headers) + \"\\n\")\n",
    "                    rows_printed = 0\n",
    "                    \n",
    "                    # Begin cleaning the files\n",
    "                    # Bytes object line to a normal string - strip and split string to list\n",
    "                    # List comprehension to remove the double quotes\n",
    "                    # Remove all null vaules\n",
    "                    for idx,line in enumerate(input_file):\n",
    "                        file_has_header = False\n",
    "                        dialect = sniffer.sniff(line.decode(\"utf-8\"))\n",
    "                        line = line.decode(\"utf-8\").strip().split(dialect.delimiter)\n",
    "                        line=[piece.replace(r'\"','') for piece in line] \n",
    "                        line=[piece.replace(r\"//N\",'') for piece in line]\n",
    "                        line=[piece.replace(r\"\\N\",'') for piece in line]\n",
    "                        line=[piece.replace(r'NULL','') for piece in line]\n",
    "                        \n",
    "                        # Make new column and get rid of the bad!\n",
    "                        if len(line) != 50 :\n",
    "                            new_column = (\"\".join(line[5:8])) \n",
    "                        \n",
    "                            del(line[5:8])\n",
    "                        \n",
    "                            line.insert(5,new_column)\n",
    "                        \n",
    "                        # For the first line (if header), do not print, otherwise, outwrite file\n",
    "                        if idx == 0:\n",
    "                            if 'datetime' in line[0]:\n",
    "                                file_has_header = True\n",
    "                        if file_has_header and idx == 0:\n",
    "                            pass #don't print the line\n",
    "                        else:\n",
    "                            outfile.write(\",\".join(line) + \"\\n\")\n",
    "                            rows_printed += 1\n",
    "print(f\"Zip-A-Dee-Doo-Da\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery \n",
    "from google.oauth2 import service_account\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/clairedanicich/Desktop/ADA/wedge/wedge2020/wedge_clean/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_wedge = os.listdir(\"wedge_clean/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication: these keys will be different on your device, must change to run your own code. \n",
    "service_path = \"/Users/clairedanicich/Desktop/ADA/wedge/wedge2020/\"\n",
    "service_file = \"MSBA-cfc85a1b18d5.json\"\n",
    "gbq_proj_id = \"msba-291619\"\n",
    "gbq_dataset_id = \"wedge2\"\n",
    "\n",
    "privatekey = service_path + service_file\n",
    "\n",
    "# Pass in credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(service_path + service_file)\n",
    "\n",
    "# Establish connection\n",
    "client = bigquery.Client(credentials = credentials, project=gbq_proj_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to see if table exists, if no table, create one\n",
    "def tbl_exists(client, table_ref) :\n",
    "    from google.cloud.exceptions import NotFound\n",
    "    try :\n",
    "        client.get_table(table_ref)\n",
    "        return True \n",
    "    except NotFound :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new table names by running through the files then uploading to GBQ\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND\n",
    "job_config.schema_update_options = [\n",
    "    # This allows us to modify the table. \n",
    "    bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_config.schema = [\n",
    "    bigquery.SchemaField(\"datetime\", \"TIMESTAMP\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"register_no\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"emp_no\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_no\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"upc\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"description\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_type\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_subtype\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_status\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"department\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"quantity\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"Scale\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"cost\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"unitPrice\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"total\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"regPrice\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"altPrice\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"tax\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"taxexempt\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"foodstamp\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"wicable\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"discount\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"memDiscount\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"discountable\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"discounttype\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"voided\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"percentDiscount\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"ItemQtty\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"volDiscType\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"volume\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"VolSpecial\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"mixMatch\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"matched\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"memType\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"staff\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"numflag\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"itemstatus\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"tenderstatus\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"charflag\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"varflag\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"batchHeaderID\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"local\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"organic\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"display\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"receipt\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"card_no\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"store\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"branch\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"match_id\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"trans_id\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "]\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "job_config.skip_leading_rows = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in clean_wedge :\n",
    "    #splits on _clean in csv files and removes rest as junk\n",
    "    my_table,junk = file.split(\"_clean\")\n",
    "\n",
    "    #creates GBQ table name\n",
    "    table_full_name = \".\".join([gbq_proj_id,gbq_dataset_id,my_table])\n",
    "\n",
    "\n",
    "    if not tbl_exists(client, table_full_name) :\n",
    "        table_ref = client.create_table(table = table_full_name)\n",
    "    else :\n",
    "        table_ref = client.get_table(table_full_name)\n",
    "    \n",
    "    table = client.get_table(table_ref)\n",
    "    print(\"Table {} contains {} columns\".format(table_ref.table_id,len(table.schema)))\n",
    "    \n",
    "    with open(file_path + file, \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(\n",
    "            source_file,\n",
    "            table_ref,\n",
    "            location=\"US\",  # Must match the destination dataset location.\n",
    "            job_config=job_config\n",
    "        )  # API request\n",
    "\n",
    "    # Waits for table load to complete.\n",
    "    job.result()  \n",
    "    print(\"Loaded {} rows into {}:{}.\".format(job.output_rows, 'wedge_example', table_ref.table_id))\n",
    "    \n",
    "    \n",
    "    # Checks the updated length of the schema\n",
    "    table = client.get_table(table)\n",
    "    print(\"Table {} now contains {} columns.\".format(table_ref.table_id, len(table.schema)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
